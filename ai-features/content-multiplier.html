---
title: 'Content Multiplier'
description: In this topic, you will learn how to utilize the Brightcove AI Content Multiplier.
parent: Plugins
layout: staging
---
<h1>{{ page.title }}</h1>
<article class="bcls-article">
  <summary>{{ page.description }}</summary>

  <section class="bcls-section">
    <h2 id="intro">Introduction</h2>
    <p>The Brightcove AI Content Multiplier allows you to quickly transform long-form videos into engaging, shorter clips tailored for different platforms. Whether you want to highlight key moments, create summaries, or convert content into vertical formats, this tool simplifies the process while maintaining the essence of your original video.</p>
  </section>
  
  <section class="bcls-section">
    <h2 id="create">Creating new clips</h2>
    <ol class="bcls-tasklist">
      <li>Navigate to the media module and select <strong>your video</strong>.
        <p></p>
        <figure class="bcls-figure">
          <img class="bcls-image" src="/assets/images/ai-features/nav-content.webp">
        </figure>
        <p></p>
        <aside class="bcls-aside bcls-aside--warning language-editable">To be clipped, source videos should be  at least 3 minutes and include spoken words.</aside>
      </li>
      
      <li>Click on the <strong>AI</strong> Button and select <strong>Clips</strong>.
        <p></p>
        <figure class="bcls-figure">
          <img class="bcls-image" src="/assets/images/ai-features/ai-dropdown.webp">
        </figure>
        <p></p>
        <p>Content you can generate with this process:</p>
        <p>
          <ul>
            <li><strong>Key Moments & Reels:</strong> Ready-to-publish clips of the most engaging excerpts from the  video. <br>The number  of clips will be determined by the model.  Key Moments will also be converted to vertical video in the form of Insta Reels (under 90 seconds) and YouTube Shorts (under 60 seconds).</li>
            <p></p>
            <li><strong>Summaries:</strong>  A concise rendering of the source video consisting of all the Key Moments stitched together.</li>
            <p></p>
            <li><strong>Reels:</strong> Key moments in vertical format.</li>
            <p></p>
            <li><strong>Chapters:</strong> All content within the source video is organized and clipped by topic.</li>
            <p></p>
            <li><strong>Original + Metadata:</strong> Add a full-length version of the original clip with metadata and transcript.</li>
          </ul>
        </p>
        <p></p>
        <aside class="bcls-aside bcls-aside--information language-editable">Key moments are selected based on relevant topics, audio intensity, and visual queues to predict your most engaging snippets.</aside>
        <!-- <figure class="bcls-figure">
            <img class="bcls-image" src="/assets/images/ai-features/clip-vertical.webp">
        </figure> -->
    </li>
    <li>
        Fill in your video's information, along with the output to generate, and click <span class="button-blue">Start</span>
        <p></p>
        <figure class="bcls-figure">
            <img class="bcls-image" src="/assets/images/ai-features/gen-clips.webp">
        </figure>
        <p></p>
        <aside class="bcls-aside bcls-aside--information language-editable">If your specific category is missing from the list, try to match the source video with the category that's closer in terms of structure.</aside>
        <p></p>
        <aside class="bcls-aside bcls-aside--warning language-editable">Please allow this process some time to complete.</aside>
    </li>
    <li>You will see this message letting you know this process has started.
      <figure class="bcls-figure">
        <img class="bcls-image" src="/assets/images/ai-features/status.webp">
      </figure>
      <aside class="bcls-aside bcls-aside--tip language-editable">You can monitor the Content Multiplier's process by looking at the custom fields section of the original video and the newly generated content. You will find this information in the (frammer_integration) custom field.<br><br>
        These are the possible status values for the original video: 
        <ul>
          <li>video_processed.inqueue</li>
          <li>video_processed.partial-success: Several clips are being generated; some of them are done, and some of them are still being processed.</li>
          <li>video_processed.success</li>
        </ul>
        <p></p>
        <ul>In your newly generated clips, you will find the next statuses in the custom fields section:
          <li>not started</li>
          <li>in progress</li>
          <li>done</li>
        </ul>
      
      </aside>
      <p></p>
      <aside class="bcls-aside bcls-aside--warning language-editable">The custom field <strong>frammer_integration</strong> cannot be edited.</aside>
    </li>

    <li>
        Once the process is completed, you will be able to see your <strong>new content</strong> as separate entities from your original video in your <strong>media module</strong>.<br><br> The generated content will contain the Title (Reels, Chapter, Summary, or Key Moment) plus ":" and the suggested title based on your clip's content.
        <p></p>
        <figure class="bcls-figure">
            <img class="bcls-image" src="/assets/images/ai-features/new-content.webp">
        </figure>
        <p></p>
        <aside class="bcls-aside bcls-aside--information language-editable">When the model does not have enough information from the video snippet to determine a title, it will default the new asset's name to "content multiplier". <br><br> You can edit the thumbnail and other aspects of the new asset; visit our <a href="https://support.brightcove.com/ai-features/content-multiplier.html#edit">Edit section</a> to learn more.</aside>
    </li>
    </section>

    <section class="bcls-section">
    <h2 id="vertical">Create a vertical video</h2>
    <ol class="bcls-tasklist-restart">
        <li>Click the <strong>AI</strong> Button and select <strong>Crop to vertical.</strong>
            <p></p>
            <figure class="bcls-figure">
                <img class="bcls-image" src="/assets/images/ai-features/crop.webp">
            </figure>
        </li>
        <p></p>
        <aside class="bcls-aside bcls-aside--warning language-editable">Original content should be shorter than 10 minutes for vertical cropping.</aside>
        <p></p>
        <li> Select your <strong>Video Type</strong> and click <span class="button-blue">Start</span>
            <p></p>
            <figure class="bcls-figure">
                <img class="bcls-image" src="/assets/images/ai-features/clip-vertical.webp">
            </figure>
            <p></p>
              <aside class="bcls-aside bcls-aside--information language-editable">If your specific category is missing from the list, try to match the source video with the category that's closer in terms of structure.</aside>
            <p></p>
        </li>
        <li>
            Once the process is completed, a <strong>vertical version</strong> of your content will appear as a separate entity in your media library.
            <p></p>
            <figure class="bcls-figure">
                <img class="bcls-image" src="/assets/images/ai-features/vertical-vid.webp">
            </figure>
            <aside class="bcls-aside bcls-aside--information language-editable">The generated content will contain the Title "Vertical:" plus the suggested title based on your clip's content.</aside>
            <aside class="bcls-aside bcls-aside--warning language-editable">Please allow this process some time to complete.</aside>
            <p></p>
        </li>
    </ol>
    
  </section>

  <section class="bcls-section">
    <h2 id="edit">Editing a content Multiplier Asset</h2>
    <p>This process can help you better align the output with your vision by:</p>
    <ul>
      <li>Emphasizing a missed phrase or idea to enhance clarity or impact.</li>
      <li>Adjusting the layout or focus in a vertical video for better composition.</li>
      <li>Shortening the video while keeping key messages for better viewer retention.</li>
    </ul>
    <p>Among other things</p>
    <h4>To edit a generated video, follow the next steps:</h4>
    <ol class="bcls-tasklist-restart">
      <li>Navigate to the media module and select <strong>your video</strong>.
        <p></p>
        <figure class="bcls-figure">
          <img class="bcls-image" src="/assets/images/ai-features/select-video.webp">
        </figure>
      </li>
      <li>Click <strong>Edit</strong> and <strong>Adjust Clip</strong>
          <p></p>
          <figure class="bcls-figure">
              <img class="bcls-image" src="/assets/images/ai-features/edit-gen-video.webp">
          </figure>
      </li>
      <li> You will be redirected to a Frammer page where you can edit your content.<br>You can find more information in <a href="https://www.frammer.com/docs/help.htm#making-changes">Frammer's documentation</a>.
          <p></p>
          <figure class="bcls-figure">
              <img class="bcls-image" src="/assets/images/ai-features/frammer-redirect.webp">
          </figure>
      </li>
      <li> After making your desired changes, click <strong>Publish to Brightcove</strong>
        <p></p>
        <figure class="bcls-figure">
            <img class="bcls-image" src="/assets/images/ai-features/frammer--publish.webp">
        </figure>
    </li>
  </section>

  <section class="bcls-section">
    <h2 id="faq">FAQ</h2>
    <h4>Is the algorithm learning from my data?</h4>
    <ul>
      <li> No, Brightcove does not store data or train models using data from your videos or account.</li>
    </ul>

    <!-- <h4>What model are you using?</h4>
    <ul>
      <li> Different models including OpenAI and Anthropic are being leveraged by CM.</li>
    </ul> -->

    <h4>How long will Frammer store my videos after processing?</h4>
    <ul>
      <li> 1 month. If the account is deactivated, Frammer will expire videos after 15 days.</li>
    </ul>

    <!-- <h4>My content is not being transformed correctly</h4>
    <ul>
      <li> Content Multiplier performs better with specific video types. If you believe that your content does not belong to any of these categories, let us know and we will contact you to refine our model.</li>
    </ul> -->

    <h4>If I edit a video in Content Multiplier and re-render it, will it be incurred in AI Credits?</h4>
    <ul>
      <li> No.</li>
    </ul>

    <h4>What are the requisites for generating clips?</h4>
    <ul>
      <li> Ideally, the video should be longer than 3 minutes and should have spoken words. Music videos are not recommended.</li>
    </ul>

    <h4>What are the requisites for cropping vertically?</h4>
    <ul>
      <li> The video should be shorter than 10 minutes.</li>
    </ul>

    <!-- <h4>For vertical video, does it capture the best camera angle?</h4>
    <ul>
      <li> To transform horizontal videos into vertical format, we leverage a proprietary computer vision model specifically trained to identify regions of interest and crop them intelligently to fit within a vertical frame. Our approach integrates business logic to optimize reframing based on the content type. For example, in interviews or podcasts, speakers are arranged within vertical grids to maintain focus, while in automobile reviews, the model ensures the vehicle—be it a car or bike—remains centered in the frame.</li>
    </ul> -->

    <h4>Does Frammer analyze a video picture or text track to decide Summary or Key Moments?</h4>
    <ul>
      <li> Key moments prioritize text but leverage some visual cues as well.</li>
    </ul>

    <h4>If it's text-based, could it be affected by loud background music with lyrics?</h4>
    <ul>
      <li> Yes, it could be impacted. The Content Multiplier's auto-captioning system is intelligent enough to distinguish one from the other, but it could impact the accuracy in some cases. The capability to denoise and reduce the impact of background noise can be activated in Frammer and will be added in future iterations.</li>
    </ul>
</section>
 
</article>
